{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis program is aim at:\\n1. implementing GAN and solve MNIST problem\\n2. trying to understand how GAN works\\n3. trying DCGAN, and find out wether sharing some of the feature spaces bettwen generater and discriminater helps\\n4. trying different training process to see which ones are more effecient and which ones fails and how\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This program is aim at:\n",
    "1. implementing GAN and solve MNIST problem\n",
    "2. trying to understand how GAN works:VanillaGAN, InfoGAN, W-GAN, ...\n",
    "3. trying DCGAN, and find out wether sharing some of the feature spaces bettwen generater and discriminater helps\n",
    "4. trying different training process to see which ones are more effecient and which ones fails and how\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from lib.netgen import full_connected\n",
    "from lib.ops import *\n",
    "\n",
    "import lib.global_config as CONF\n",
    "TENSORBOARD_ROOT = os.path.join(CONF.SYS_ROOT, \"tensorboard\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /notebooks/datasets/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting /notebooks/datasets/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /notebooks/datasets/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /notebooks/datasets/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# import mnist data sets\n",
    "mnist = input_data.read_data_sets(os.path.join(CONF.SYS_ROOT, \"datasets/mnist_data/\"), one_hot=True)\n",
    "\n",
    "# input data is a 28X28=784 note vector\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "INPUT_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\n",
    "# output data is a 10-class label verctor\n",
    "LABEL_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Abstractions ###########\n",
    "class AbsGAN(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        self._discriminater = None\n",
    "        self._generater = None\n",
    "        \n",
    "        self.d_optm = None\n",
    "        self.g_optm = None\n",
    "        self.d_loss = None\n",
    "        self.g_loss = None\n",
    "        \n",
    "        self.d_summaries = None\n",
    "        self.g_summaries = None\n",
    "        \n",
    "    def _setup(self):\n",
    "        raise Exception(\"Not yet implemented!\")\n",
    "        \n",
    "    def setup(self):\n",
    "        self._setup()\n",
    "        \n",
    "        assert self._discriminater is not None\n",
    "        assert self._generater is not None\n",
    "        assert self.d_optm is not None\n",
    "        assert self.g_optm is not None\n",
    "        assert self.d_loss is not None\n",
    "        assert self.d_r_loss is not None\n",
    "        assert self.d_f_loss is not None\n",
    "        assert self.g_loss is not None\n",
    "        \n",
    "    def get_optms(self):\n",
    "        return self.d_optm, self.g_optm\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.d_loss, self.d_r_loss, self.d_f_loss, self.g_loss\n",
    "    \n",
    "    def create_input_summary(self):\n",
    "        raise Exception(\"Not yet implemented!\")\n",
    "        \n",
    "    def get_summaries(self):\n",
    "        if self.d_summaries is not None:\n",
    "            assert self.g_summaries is not None\n",
    "            \n",
    "            return self.d_summaries, self.g_summaries\n",
    "        \n",
    "        d_input_summ, g_input_summ = self.create_input_summary()\n",
    "        \n",
    "        self.d_summaries = tf.summary.merge([\n",
    "            self._discriminater.summary(),\n",
    "            d_input_summ\n",
    "        ])\n",
    "        \n",
    "        self.g_summaries = tf.summary.merge([\n",
    "            self._generater.summary(),\n",
    "            g_input_summ\n",
    "        ])\n",
    "        \n",
    "        return self.d_summaries, self.g_summaries\n",
    "    \n",
    "    \n",
    "class AbsModel(object):\n",
    "    def __init__(self, name, type_alias):\n",
    "        self.name = name\n",
    "        self.type_alias = type_alias\n",
    "        \n",
    "        self.summaries = []\n",
    "        self.merged_summary = None\n",
    "        \n",
    "        self.vars_initialized = False\n",
    "            \n",
    "    def namescope(self):\n",
    "        return \"{}_{}\".format(self.name, self.type_alias)\n",
    "\n",
    "    def varscope(self):\n",
    "        return \"{}_{}_vars\".format(self.name, self.type_alias)\n",
    "    \n",
    "    def reuse_vars(self, vs):\n",
    "        if self.vars_initialized:\n",
    "            print \">> Reusing variables in {} <<\\n\".format(vs.name)\n",
    "            vs.reuse_variables()\n",
    "        else:\n",
    "            print \">> Initializing variables in {} <<\\n\".format(vs.name)\n",
    "            self.vars_initialized = True\n",
    "        \n",
    "    def add_summary(self, *s):\n",
    "        self.summaries.extend(s)\n",
    "        \n",
    "    def summary(self):\n",
    "        if self.merged_summary is not None:\n",
    "            return self.merged_summary\n",
    "\n",
    "        self.merged_summary = tf.summary.merge(self.summaries)\n",
    "        return self.merged_summary\n",
    "    \n",
    "    \n",
    "class GeneraterSampler(object):\n",
    "    def __init__(self, z, sample_num, z_dim):\n",
    "        self.sample_num = sample_num\n",
    "        self.z = z\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "    def setup(self, fake_images):\n",
    "        self.fake_image_sammary = tf.summary.image(\"Fake_Images_Sample\", fake_images, self.sample_num)\n",
    "        \n",
    "    def sample(self, sess, i):\n",
    "        sample_z = np.random.uniform(-1, 1, size=(self.sample_num, self.z_dim))\n",
    "        return sess.run(self.fake_image_sammary, feed_dict={self.z: sample_z})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Basic GAN, only distinguish fake/real ##############\n",
    "class VanillaGAN(AbsGAN):\n",
    "    D_LEARNING_RATE = 0.00005\n",
    "    D_FEATURE_DEPTH_STARTER = 32\n",
    "    D_KSIZE = 3\n",
    "    D_FEATURE_SPACE_DEPTH = 5\n",
    "    \n",
    "    G_LEARNING_RATE = 0.00005\n",
    "    G_FEATURE_DEPTH_STARTER = 32\n",
    "    G_KSIZE = 3\n",
    "    G_FEATURE_SPACE_DEPTH = 5\n",
    "    \n",
    "    ## Discriminator ##\n",
    "    class D(AbsModel):\n",
    "        def __init__(self, name, image_size, n_channels, dim_y, dim_z):\n",
    "            AbsModel.__init__(self, name, \"D\")\n",
    "            \n",
    "            self.image_size = image_size\n",
    "            self.n_channels = n_channels\n",
    "            self.dim_y = dim_y\n",
    "            self.dim_z = dim_z\n",
    "            \n",
    "        def define_graph(self, images):\n",
    "            with tf.variable_scope(self.varscope()) as vs:\n",
    "                self.reuse_vars(vs)\n",
    "                \n",
    "                conv_in_activations = []\n",
    "                conv_in_weights = []\n",
    "                conv_in_bias = []\n",
    "                conv_out_activations = []\n",
    "                conv_out_weights = []\n",
    "                conv_out_bias = []\n",
    "                    \n",
    "                # FIXME: should not let tf do reshaping\n",
    "                input_image_shape = images.get_shape().as_list()\n",
    "                if input_image_shape[1] != self.image_size or input_image_shape[2] != self.image_size:\n",
    "                    head = tf.image.resize_images(\n",
    "                        images, [self.image_size, self.image_size]\n",
    "                    )\n",
    "                else:\n",
    "                    head = images\n",
    "                    \n",
    "                #### in ####\n",
    "                featured_layers = []\n",
    "                feature_depth = VanillaGAN.D_FEATURE_DEPTH_STARTER\n",
    "                for _ in range(VanillaGAN.D_FEATURE_SPACE_DEPTH - 1):\n",
    "                    head, layer, a, w, b = conv2d_pool(\"conv_in_{}\".format(feature_depth),\n",
    "                                                       head,\n",
    "                                                       VanillaGAN.D_KSIZE, feature_depth,\n",
    "                                                       activation=tf.nn.sigmoid,\n",
    "                                                       more=True)\n",
    "                    \n",
    "                    conv_in_activations.append(a)\n",
    "                    conv_in_weights.append(w)\n",
    "                    conv_in_bias.append(b)\n",
    "                    \n",
    "                    featured_layers.append(layer)\n",
    "                    feature_depth *= 2\n",
    "\n",
    "                #### turning ####\n",
    "                head, a, w, b = conv2d_norm(\"conv_in_{}\".format(feature_depth),\n",
    "                                            head,\n",
    "                                            VanillaGAN.D_KSIZE, feature_depth,\n",
    "                                            activation=tf.nn.sigmoid,\n",
    "                                            more=True)\n",
    "                \n",
    "                conv_in_activations.append(a)\n",
    "                conv_in_weights.append(w)\n",
    "                conv_in_bias.append(b)\n",
    "\n",
    "                #### out ####\n",
    "                featured_layers.reverse()\n",
    "                for i in range(0, len(featured_layers)):\n",
    "                    feature_depth /= 2\n",
    "                    head, a, w, b = cat_conv2d(\"conv_out_{}\".format(feature_depth),\n",
    "                                               [featured_layers[i], head],\n",
    "                                               VanillaGAN.D_KSIZE, feature_depth,\n",
    "                                               activation=tf.nn.relu,\n",
    "                                               more=True)\n",
    "                    \n",
    "                    conv_out_activations.append(a)\n",
    "                    conv_out_weights.append(w)\n",
    "                    conv_out_bias.append(b)\n",
    "\n",
    "                #### flatten ####\n",
    "                flattened, node_num, w, b = conv2d_one(\"flatten\",\n",
    "                                                       head,\n",
    "                                                       activation=tf.nn.sigmoid,\n",
    "                                                       more=True)\n",
    "\n",
    "                #### full-connected ####\n",
    "                fc = full_connected([\n",
    "                    (self.dim_y, tf.nn.relu)\n",
    "                ])\n",
    "\n",
    "                outputs, fc_ws, fc_bs, fc_outs = fc.gen(flattened, node_num, name=\"fc\")\n",
    "                \n",
    "            # summary\n",
    "            with tf.name_scope(self.namescope()):\n",
    "                self.add_summary(\n",
    "                    tf.summary.histogram(\"weights_flatten\", w),\n",
    "                    tf.summary.histogram(\"biases_flatten\", b),\n",
    "                    tf.summary.histogram(\"activations_flatten\", flattened)\n",
    "                )\n",
    "\n",
    "                for fc_w in fc_ws:\n",
    "                    self.add_summary( tf.summary.histogram(\"weights_fc\", fc_w) )\n",
    "                for fc_b in fc_bs:\n",
    "                    self.add_summary( tf.summary.histogram(\"biases_fc\", fc_b) )\n",
    "                for fc_out in fc_outs:\n",
    "                    self.add_summary( tf.summary.histogram(\"outputs_fc\", fc_out) )\n",
    "\n",
    "                for a in conv_in_activations:\n",
    "                    self.add_summary( tf.summary.histogram(\"conv_in_activation\", a) )\n",
    "                for w in conv_in_weights:\n",
    "                    self.add_summary( tf.summary.histogram(\"conv_in_weights\", w) )\n",
    "                for b in conv_in_bias:\n",
    "                    self.add_summary( tf.summary.histogram(\"conv_in_bias\", b) )\n",
    "                for a in conv_out_activations:\n",
    "                    self.add_summary( tf.summary.histogram(\"conv_out_activation\", a) )\n",
    "                for w in conv_out_weights:\n",
    "                    self.add_summary( tf.summary.histogram(\"conv_out_weights\", w) )\n",
    "                for b in conv_out_bias:\n",
    "                    self.add_summary( tf.summary.histogram(\"conv_out_bias\", b) )\n",
    "                \n",
    "            return outputs\n",
    "            \n",
    "        def define_optimize(self, real_output, fake_output):\n",
    "            with tf.name_scope(self.namescope() + \"_real_loss\"):\n",
    "                real_loss = cross_entropy(real_output, tf.ones_like(real_output))\n",
    "\n",
    "            with tf.name_scope(self.namescope() + \"_fake_loss\"):\n",
    "                fake_loss = cross_entropy(fake_output, tf.zeros_like(fake_output))\n",
    "\n",
    "            # D loss\n",
    "            with tf.name_scope(self.namescope() + \"_loss\") as ns:\n",
    "                loss = real_loss + fake_loss\n",
    "            \n",
    "            # find trainable variables\n",
    "            trainable = [var for var in tf.trainable_variables() if self.varscope() in var.name]\n",
    "            print \"Training variables in {}:\".format(self.varscope())\n",
    "            for var in trainable:\n",
    "                print var\n",
    "                \n",
    "            with tf.name_scope(self.namescope() + \"_optimizer\") as ns:\n",
    "                optim = tf.train.AdamOptimizer(\n",
    "                    VanillaGAN.D_LEARNING_RATE\n",
    "                ).minimize(\n",
    "                    loss, var_list=trainable\n",
    "                )\n",
    "            \n",
    "            # summary\n",
    "            with tf.name_scope(self.namescope()):\n",
    "                self.add_summary( tf.summary.scalar(\"loss_real_discriminater\", real_loss) )\n",
    "                self.add_summary( tf.summary.scalar(\"loss_fake_discriminater\", fake_loss) )\n",
    "                self.add_summary( tf.summary.scalar(\"loss_discriminater\", loss) )\n",
    "            \n",
    "            self.loss = loss\n",
    "            \n",
    "            return optim, self.loss, real_loss, fake_loss\n",
    "        ######### End Discriminater #########\n",
    "        \n",
    "        \n",
    "    ## Generator ##\n",
    "    class G(AbsModel):\n",
    "        def __init__(self, name, image_size, n_channels, dim_z, batch_size):\n",
    "            AbsModel.__init__(self, name, \"G\")\n",
    "            \n",
    "            self.image_size = image_size\n",
    "            self.n_channels = n_channels\n",
    "            self.dim_z = dim_z\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "            \n",
    "        def define_graph(self, z):\n",
    "            deconv_activations = []\n",
    "            deconv_weights = []\n",
    "            deconv_bias = []\n",
    "            \n",
    "            with tf.variable_scope(self.varscope()) as vs:\n",
    "                self.reuse_vars(vs)\n",
    "                    \n",
    "                # find out each de-conv's shape\n",
    "                fake_image_shape = [self.image_size, self.image_size, self.n_channels]\n",
    "                feature_layers_shapes = []\n",
    "                \n",
    "                def shape_conv2d(input_shape, feature_depth):\n",
    "                    return [input_shape[0] / 2, input_shape[1] / 2, feature_depth]\n",
    "                \n",
    "                prev_shape = fake_image_shape\n",
    "                feature_depth = VanillaGAN.G_FEATURE_DEPTH_STARTER\n",
    "                for _ in range(VanillaGAN.G_FEATURE_SPACE_DEPTH):\n",
    "                    next_shape = shape_conv2d(prev_shape, feature_depth)\n",
    "                    feature_layers_shapes.append(next_shape)\n",
    "                    prev_shape = next_shape\n",
    "                    feature_depth *= 2\n",
    "                    \n",
    "                feature_layers_shapes.reverse()\n",
    "                \n",
    "                # full-connect to the last feature layers\n",
    "                last_layer_shape = feature_layers_shapes[0]\n",
    "                last_layer_len = last_layer_shape[0] * last_layer_shape[1] * last_layer_shape[2]\n",
    "                \n",
    "                fc = full_connected([\n",
    "                    (last_layer_len, tf.nn.relu)\n",
    "                ])\n",
    "\n",
    "                last_layer, fc_ws, fc_bs, fc_outs = fc.gen(z, self.dim_z, name=\"fc\")\n",
    "                \n",
    "                # un-flatten\n",
    "                conv_layer = tf.reshape(last_layer, [-1] + last_layer_shape)\n",
    "                \n",
    "                # de-conv\n",
    "                batch_size = -1 #TODO: maybe need to be given?\n",
    "                for i in range(1, len(feature_layers_shapes)):\n",
    "                    output_image_shape = feature_layers_shapes[i]\n",
    "                    output_shape = [self.batch_size] + output_image_shape\n",
    "                    \n",
    "                    conv_layer, a, w, b = deconv2d(\"{}x{}x{}\".format(*output_image_shape),\n",
    "                                                   conv_layer, output_shape, VanillaGAN.G_KSIZE,\n",
    "                                                   activation=tf.nn.relu,\n",
    "                                                   more=True)\n",
    "                    \n",
    "                    deconv_activations.append(a)\n",
    "                    deconv_weights.append(w)\n",
    "                    deconv_bias.append(b)\n",
    "                    \n",
    "                # final image\n",
    "                fake_images, fi_a, fi_w, fi_b = deconv2d(\"fake_images\",\n",
    "                                                conv_layer,\n",
    "                                                [self.batch_size] + fake_image_shape,\n",
    "                                                VanillaGAN.G_KSIZE,\n",
    "                                                more=True)\n",
    "                \n",
    "                fake_images = tf.nn.tanh(fake_images)\n",
    "                \n",
    "            # summary\n",
    "            with tf.name_scope(self.namescope()):\n",
    "                for fc_out in fc_outs:\n",
    "                    self.add_summary( tf.summary.histogram(\"fc_activations\", fc_out) )\n",
    "                for fc_w in fc_ws:\n",
    "                    self.add_summary( tf.summary.histogram(\"fc_weights\", fc_w) )\n",
    "                for fc_b in fc_bs:\n",
    "                    self.add_summary( tf.summary.histogram(\"fc_bias\", fc_b) )\n",
    "                    \n",
    "                for a in deconv_activations:\n",
    "                    self.add_summary( tf.summary.histogram(\"deconv_activations\", a) )\n",
    "                for w in deconv_weights:\n",
    "                    self.add_summary( tf.summary.histogram(\"deconv_weights\", w) )\n",
    "                for b in deconv_bias:\n",
    "                    self.add_summary( tf.summary.histogram(\"deconv_bias\", b) )\n",
    "                    \n",
    "                self.add_summary( tf.summary.histogram(\"fake_image_activations\", fi_a) )\n",
    "                self.add_summary( tf.summary.histogram(\"fake_image_weights\", fi_w) )\n",
    "                self.add_summary( tf.summary.histogram(\"fake_image_bias\", fi_b) )\n",
    "                \n",
    "            return fake_images\n",
    "        \n",
    "        def define_optimize(self, fake_output):\n",
    "            with tf.name_scope(self.namescope() + \"_loss\") as ns:\n",
    "                loss = cross_entropy(\n",
    "                    fake_output, tf.ones_like(fake_output)\n",
    "                )\n",
    "                \n",
    "            # find trainable variables\n",
    "            trainable = [var for var in tf.trainable_variables() if self.varscope() in var.name]\n",
    "            print \"Training variables in {}:\".format(self.varscope())\n",
    "            for var in trainable:\n",
    "                print var\n",
    "            \n",
    "            with tf.name_scope(self.namescope() + \"_optimize\") as ns:\n",
    "                optim = tf.train.AdamOptimizer(\n",
    "                    VanillaGAN.G_LEARNING_RATE\n",
    "                ).minimize(\n",
    "                    loss,\n",
    "                    var_list=trainable\n",
    "                )\n",
    "            \n",
    "            with tf.name_scope(self.namescope()):\n",
    "                self.add_summary(tf.summary.scalar(\"loss_generater\", loss))\n",
    "            \n",
    "            self.loss = loss\n",
    "            \n",
    "            return optim, self.loss\n",
    "        ################ End Generater ###############\n",
    "    \n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super(VanillaGAN, self).__init__(name)\n",
    "        self.fake_images = None\n",
    "        \n",
    "    def init(self, raw_image_width, raw_image_height, image_size, n_channels, dim_y, dim_z, batch_size):\n",
    "        with tf.name_scope(\"inputs\") as scope:\n",
    "            self.z = tf.placeholder(tf.float32,\n",
    "                                    shape=[None, dim_z],\n",
    "                                    name=\"Z\")\n",
    "            self.real_images = tf.placeholder(tf.float32,\n",
    "                                              shape=[None, raw_image_width, raw_image_height, n_channels],\n",
    "                                              name=\"real_images\")\n",
    "            \n",
    "        self._discriminater = VanillaGAN.D(self.name, image_size, n_channels, dim_y, dim_z)\n",
    "        self._generater = VanillaGAN.G(self.name, image_size, n_channels, dim_z, batch_size)\n",
    "        self._sampler = GeneraterSampler(self.z, batch_size, dim_z)\n",
    "        \n",
    "    def setup(self):\n",
    "        self.fake_images = self._generater.define_graph(self.z)\n",
    "        \n",
    "        real_output = self._discriminater.define_graph(self.real_images)\n",
    "        fake_output = self._discriminater.define_graph(self.fake_images)\n",
    "        \n",
    "        self.g_optm, self.g_loss = self._generater.define_optimize(fake_output)\n",
    "        self.d_optm, self.d_loss, self.d_r_loss, self.d_f_loss = self._discriminater.define_optimize(real_output, fake_output)\n",
    "        \n",
    "        self._sampler.setup(self.fake_images)\n",
    "        \n",
    "    def create_input_summary(self):\n",
    "        assert self.z is not None \n",
    "        assert self.real_images is not None\n",
    "        assert self.fake_images is not None\n",
    "        \n",
    "        # summary fake imagess\n",
    "        summary_fake_images_d = tf.summary.image(\n",
    "            \"Fake_Images_Discriminated\",\n",
    "            self.fake_images, 5)\n",
    "        summary_fake_images_g = tf.summary.image(\n",
    "            \"Fake_Images_Generated\",\n",
    "            self.fake_images, 5)\n",
    "        \n",
    "        sum_hist_fake_iamge_d = tf.summary.histogram(\"Fake_Image_Hist_D\", self.fake_images)\n",
    "        sum_hist_fake_iamge_g = tf.summary.histogram(\"Fake_Image_Hist_G\", self.fake_images)\n",
    "        \n",
    "        summary_z = tf.summary.histogram(\"Z\", self.z)\n",
    "        summary_real_images = tf.summary.image(\"Real_Images\", self.real_images, 5)\n",
    "        \n",
    "        d_summ = tf.summary.merge([\n",
    "            summary_z,\n",
    "            summary_real_images,\n",
    "            summary_fake_images_d,\n",
    "            sum_hist_fake_iamge_d\n",
    "        ])\n",
    "        g_summ = tf.summary.merge([\n",
    "            summary_z,\n",
    "            summary_fake_images_g,\n",
    "            sum_hist_fake_iamge_g\n",
    "        ])\n",
    "        \n",
    "        return d_summ, g_summ\n",
    "        \n",
    "    def feed_discriminater(self, **kwarg):\n",
    "        images = kwarg[\"images\"]\n",
    "        z = kwarg[\"z\"]\n",
    "        \n",
    "        return {self.real_images: images, self.z: z}\n",
    "    \n",
    "    def feed_generater(self, **kwarg):\n",
    "        z = kwarg[\"z\"]\n",
    "        \n",
    "        return {self.z: z}\n",
    "    \n",
    "    def sample(self, sess, i):\n",
    "        return self._sampler.sample(sess, i)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Info-GAN,distingwish fake/real & labels ##############\n",
    "class InfoGAN:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training configurations\n",
    "DEFAULT_CONF = {\n",
    "    \"TRAINING_TIMES\": 30000,\n",
    "    \"SUMMARY_FREQ\": 50,\n",
    "    \"MODEL_SAVE_FREQ\": 500,\n",
    "    \"BATCH_SIZE\": 150,\n",
    "    \"RAW_IMAGE_WIDTH\": 28,\n",
    "    \"RAW_IMAGE_HEIGHT\": 28,\n",
    "    \"IMAGE_SIZE\": 32,\n",
    "    \"N_CHAN\": 1,\n",
    "    \"Y_DIM\": 10,\n",
    "    \"Z_DIM\": 10,\n",
    "    \"SAMPLE_FREQ\": 200,\n",
    "    \"TRAINING_MODE\": \"D1G2\", # \"D1G1\", \"D1G2\", \"LOSS_THRESHOLD\" ...\n",
    "    # loss threshold arguments\n",
    "    \"LOSS_THRESHOLD_STARTER\": None,\n",
    "    \"LOSS_THRESHOLD_FACTOR\": 0.8,\n",
    "    \"DISCRIMINATER_FIRST\": True\n",
    "}\n",
    "\n",
    "# Training\n",
    "def train(task_name, gan, conf={}):\n",
    "    # configurations\n",
    "    conf = merge_conf(conf, DEFAULT_CONF)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # initialize gan\n",
    "    #TODO: need to switch gan types here while doing gan.init\n",
    "    gan.init(conf[\"RAW_IMAGE_WIDTH\"],\n",
    "             conf[\"RAW_IMAGE_HEIGHT\"],\n",
    "             conf[\"IMAGE_SIZE\"],\n",
    "             conf[\"N_CHAN\"],\n",
    "             conf[\"Y_DIM\"],\n",
    "             conf[\"Z_DIM\"],\n",
    "             conf[\"BATCH_SIZE\"])\n",
    "    \n",
    "    if conf[\"TRAINING_MODE\"] == \"LOSS_THRESHOLD\":\n",
    "        loss_threshold = conf[\"LOSS_THRESHOLD_STARTER\"]\n",
    "        D_turn = conf[\"DISCRIMINATER_FIRST\"]\n",
    "    \n",
    "    D_loss = None\n",
    "    G_loss = None\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print \"Setup...\"\n",
    "        gan.setup()\n",
    "        \n",
    "        # prepare D & G\n",
    "        D_optm, G_optm = gan.get_optms()\n",
    "        D_l, D_r_l, D_f_l, G_l = gan.get_loss()\n",
    "        D_summ, G_summ = gan.get_summaries()\n",
    "        \n",
    "        # tensorboard & saver\n",
    "        tensorboard_save_path = os.path.join(TENSORBOARD_ROOT, task_name)\n",
    "        writer = tf.summary.FileWriter(tensorboard_save_path)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # record graph\n",
    "        writer.add_graph(sess.graph)\n",
    "\n",
    "        # initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        init.run()\n",
    "\n",
    "        print \"Now training...\"\n",
    "        print \"Run `tensorboard --logdir=%s` to see more information.\" % TENSORBOARD_ROOT\n",
    "        # training process\n",
    "        for i in xrange(conf[\"TRAINING_TIMES\"]):\n",
    "            # batching data & format data\n",
    "            batch_inputs, batch_labels = mnist.train.next_batch(conf[\"BATCH_SIZE\"])\n",
    "            batch_images = np.reshape(batch_inputs, \n",
    "                                      (conf[\"BATCH_SIZE\"],\n",
    "                                       conf[\"RAW_IMAGE_WIDTH\"],\n",
    "                                       conf[\"RAW_IMAGE_HEIGHT\"],\n",
    "                                       conf[\"N_CHAN\"]))\n",
    "            \n",
    "            batch_z_D = np.random.uniform(-1, 1, size=(conf[\"BATCH_SIZE\"], conf[\"Z_DIM\"]))\n",
    "            batch_z_G = np.random.uniform(-1, 1, size=(conf[\"BATCH_SIZE\"], conf[\"Z_DIM\"]))\n",
    "            \n",
    "            feed_dict_D = gan.feed_discriminater(images=batch_images, z=batch_z_D)\n",
    "            feed_dict_G = gan.feed_generater(z=batch_z_G)\n",
    "            \n",
    "            # optimize D\n",
    "            def optimize_d():\n",
    "                if i % conf[\"SUMMARY_FREQ\"] == 0:\n",
    "                    _, D_loss, s = sess.run([D_optm, D_r_l, D_summ], feed_dict=feed_dict_D)\n",
    "                    writer.add_summary(s, i)\n",
    "                    # print \"Add summary for Discriminater at {}\".format(i)\n",
    "                    print \"D loss:[{}]\".format(D_loss)\n",
    "                else:\n",
    "                    _, D_loss = sess.run([D_optm, D_l], feed_dict=feed_dict_D)\n",
    "                    \n",
    "            # optimize G\n",
    "            def optimize_g():\n",
    "                if i % conf[\"SUMMARY_FREQ\"] == 0:\n",
    "                    _, G_loss, s = sess.run([G_optm, G_l, G_summ], feed_dict=feed_dict_G)\n",
    "                    writer.add_summary(s, i)\n",
    "                    # print \"Add summary for Generater at {}\".format(i)\n",
    "                    print \"G loss:[{}]\".format(G_loss)\n",
    "                else:\n",
    "                    _, G_loss = sess.run([G_optm, G_l], feed_dict=feed_dict_G)    \n",
    "               \n",
    "            # ---------- training mode : LOSS_THRESHOLD ---------- \n",
    "            if conf[\"TRAINING_MODE\"] == \"LOSS_THRESHOLD\":\n",
    "                if D_turn:\n",
    "                    optimize_d()\n",
    "                else:\n",
    "                    optimize_g()\n",
    "\n",
    "                # decide turning\n",
    "                if loss_threshold is None:\n",
    "                    if D_turn:\n",
    "                        loss_threshold = D_loss * conf[\"LOSS_THRESHOLD_FACTOR\"]\n",
    "                    else:\n",
    "                        loss_threshold = G_loss * conf[\"LOSS_THRESHOLD_FACTOR\"]\n",
    "\n",
    "                if D_turn and D_loss < loss_threshold:\n",
    "                    D_turn = False\n",
    "                    loss_threshold = None\n",
    "                    print \"Turning to G at {} with loss [{}]\".format(i, D_loss)\n",
    "                elif not D_turn and G_loss < loss_threshold:\n",
    "                    D_turn = True\n",
    "                    loss_threshold = None\n",
    "                    print \"Turning to D at {} with loss [{}]\".format(i, G_loss)\n",
    "                    \n",
    "            # ---------- training mode : D1G2 ----------\n",
    "            elif conf[\"TRAINING_MODE\"] == \"D1G2\":\n",
    "                optimize_d()\n",
    "                optimize_g()\n",
    "                optimize_g()\n",
    "                \n",
    "            # ---------- training mode : D1G1 ----------\n",
    "            else:\n",
    "                optimize_d()\n",
    "                optimize_g()\n",
    "                \n",
    "            # sampling\n",
    "            if i % conf[\"SAMPLE_FREQ\"] == 0:\n",
    "                s = gan.sample(sess, i)\n",
    "                writer.add_summary(s, i)\n",
    "                \n",
    "            # save model\n",
    "            if i % conf[\"MODEL_SAVE_FREQ\"] == 0:\n",
    "                saver.save(sess, os.path.join(TENSORBOARD_ROOT, \"model_{}.ckpt\".format(task_name)), i)\n",
    "                # print \"Model saved at {}\".format(i)\n",
    "                \n",
    "            if i % int(conf[\"TRAINING_TIMES\"] / 50) == 0:\n",
    "                print \"processing[{}%]...\".format(i * 10000 / conf[\"TRAINING_TIMES\"] / 100.0)\n",
    "                \n",
    "        print \"All processes done.\"\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup...\n",
      ">> Initializing variables in GAN3_G_vars <<\n",
      "\n",
      ">> Initializing variables in GAN3_D_vars <<\n",
      "\n",
      "generating convolution layer:conv_in_32\n",
      "generating convolution layer:conv_in_64\n",
      "generating convolution layer:conv_in_128\n",
      "generating convolution layer:conv_in_256\n",
      "generating convolution layer:conv_in_512\n",
      "generating convolution layer:conv_out_256\n",
      "generating convolution layer:conv_out_128\n",
      "generating convolution layer:conv_out_64\n",
      "generating convolution layer:conv_out_32\n",
      "generating convolution layer:flatten\n",
      ">> Reusing variables in GAN3_D_vars <<\n",
      "\n",
      "generating convolution layer:conv_in_32\n",
      "generating convolution layer:conv_in_64\n",
      "generating convolution layer:conv_in_128\n",
      "generating convolution layer:conv_in_256\n",
      "generating convolution layer:conv_in_512\n",
      "generating convolution layer:conv_out_256\n",
      "generating convolution layer:conv_out_128\n",
      "generating convolution layer:conv_out_64\n",
      "generating convolution layer:conv_out_32\n",
      "generating convolution layer:flatten\n",
      "Training variables in GAN3_G_vars:\n",
      "<tf.Variable 'GAN3_G_vars/weights:0' shape=(10, 512) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/bias:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/w_2x2x256:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/biases_2x2x256:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/w_4x4x128:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/biases_4x4x128:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/w_8x8x64:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/biases_8x8x64:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/w_16x16x32:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/biases_16x16x32:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/w_fake_images:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_G_vars/biases_fake_images:0' shape=(1,) dtype=float32_ref>\n",
      "Training variables in GAN3_D_vars:\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_in_32:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_in_32:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_in_64:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_in_64:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_in_128:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_in_128:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_in_256:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_in_256:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_in_512:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_in_512:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_out_256:0' shape=(3, 3, 768, 256) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_out_256:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_out_128:0' shape=(3, 3, 384, 128) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_out_128:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_out_64:0' shape=(3, 3, 192, 64) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_out_64:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_conv_out_32:0' shape=(3, 3, 96, 32) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_conv_out_32:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights_flatten:0' shape=(32, 32, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias_flatten:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/weights:0' shape=(32, 10) dtype=float32_ref>\n",
      "<tf.Variable 'GAN3_D_vars/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Now training...\n",
      "Run `tensorboard --logdir=/notebooks/tensorboard` to see more information.\n",
      "D loss:[None], G loss:[None]\n",
      "processing[0.0%]...\n",
      "D loss:[None], G loss:[None]\n",
      "D loss:[None], G loss:[None]\n",
      "D loss:[None], G loss:[None]\n",
      "processing[2.0%]...\n",
      "D loss:[None], G loss:[None]\n",
      "D loss:[None], G loss:[None]\n",
      "D loss:[None], G loss:[None]\n",
      "processing[4.0%]...\n",
      "D loss:[None], G loss:[None]\n",
      "D loss:[None], G loss:[None]\n",
      "D loss:[None], G loss:[None]\n",
      "processing[6.0%]...\n",
      "D loss:[None], G loss:[None]\n"
     ]
    }
   ],
   "source": [
    "train(\"VanillaGAN-20171023-1505\", VanillaGAN(\"GAN3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
